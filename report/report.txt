Datasets & tools (1 page)

Which data sets are you going to use?
Why is this data good for these experiments?
Is the data possible biased and how does this affect the experiments?


\begin{tabular}{|l|c|l|l|l|l|l}\hline
	 & DataSet-1   & DataSet-2 & DataSet-3 & DataSet-4 & DataSet-5    \\\hline
  Assortativity Coef. & ?? & ?? & ?? & ?? & ?? \\\hline
  Clustering Coef. & ?? & ?? & ?? & ?? & ?? \\\hline
  Average degree & ?? & ?? & ?? & ?? & ?? \\\hline
  Size of nodes & ?? & ?? & ?? & ?? & ?? \\\hline
  Size of Edeges & ?? & ?? & ?? & ?? & ?? \\\hline
\end{tabular}



Almost all link prediction works need to verify their methods on the collected datasets. The datasets are important for fairly reproducing and comparing different link prediction methods. Constructing and collecting the datasets is a time-consuming and labor-intensive work. That said, not all the datasets are publicly available to use and some of the sets are either incomplete or missing values. As mentioned in the sub-section Constructing Data Sets the dataset needs splitting into training sets and testing sets and to link-predict correctly our focus lies specifically on datasets with timestamps attached to each set of points this way we can easily check if a set exists in training set and test set given the dates of, for instances two authors previously worked together and might work together in the near future. 

During scouting on the web for datasets we came across several useful datasets to which we think we can work with and produce some results with it. In the table below we summarize 5 datasets we used for link prediction. As you might notice, most of the sets are coming from konect such as the UC Irvine messages [1] which is an directed network contains sent messages between the users of an on-line community of students from the University of California. Others, such as Digg [2] which is a reply network of the social news website in which each node in the network is a user of the website, and each directed edge denotes that a user replied to another user. Those are by far the most used and popular sources of datasets. Other sets such as [3] Dublin Contacts is a A human contact network where nodes represent humans and edges between them represent proximity (i.e., contacts in the physical world) and [4] IA-Reality-call is more a Reality mining network data consists of human mobile phone call events between a small set of core users at the Massachusetts Institute of Technology (MIT) whom actually were assigned mobile phones for which all calls were collected. And finally Math Overflow temporal network [5], a temporal network of interactions on the stack exchange web site Math Overflow.

Some of the sets we came across are either outdated or incomplete to so degree which was unusable. The social network datasets however are well maintained by some of the major datasets distributors such as Stanford University, this due that most of the researchers prefer to use these datasets. During the experimentation phase we noticed that some of sets contain noise\footnote{Noise make the networks inconsistent to the real-world networks.} and so a clean-up is required before usage. ~~And, when same metrics are compared on different datasets their performance ranks are usually not consistent or even various greatly~~. 

Although there are many link prediction metrics and methods proposed, only very few works open their source codes. People have to re-implement some complicate methods, and that is a time-consuming process. Only few public tools try to integrate these metrics and methods such as linkpred [6] and LPmade [7] which both have great resources and handful of link prediction metrics. It is very important for selecting the appropriate metrics or methods for a link prediction task. For instance, LPmade, which is a cross-platform software solution, provides multi-core link prediction and related tasks and analysis. First, it is a scalable library which implements most commonly used unsupervised link prediction metrics, especially, all implementations have high performances. Second, it supports automatic link prediction processes including prediction, evaluation, and network analysis. Linkpred on the other hand is an open-source, also cross-platform, provides command-line tool and most of the predictors link prediction offers. Its tested by number of researchers and easy to use. Its pure python library, which could be slow at some point with larger datasets whereas LPmade on the other is pure C++ and obviously much faster in terms of calculations, but requires extensive C++ knowledge in order to use it properly. 


[1] http://konect.uni-koblenz.de/networks/opsahl-ucsocial
[2] http://konect.uni-koblenz.de/networks/munmun_digg_reply
[3] http://networkrepository.com/ia-contacts-dublin.php
[4] http://networkrepository.com/ia-contacts-dublin.php
[5] http://snap.stanford.edu/data/sx-mathoverflow.html 
[6] https://github.com/rafguns/linkpred
[7] https://github.com/rlichtenwalter/LPmade
